<!DOCTYPE html>
<html lang="en-us">
	<head>
		<meta charset="UTF-8">
		<title>INFOTABS</title>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="theme-color" content="#157879">
		<link rel="stylesheet" href="css/normalize.css">
		<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
		<link rel="stylesheet" href="css/cayman.css">
	</head>
	<body>
		<section class="page-header">
			<!-- <h1><img src="figures/logo.png" style="max-width:40%;"></h1> -->
			<h1 class="project-name">InfoSync</h1>
			<a href="https://www.aclweb.org/anthology/2020.acl-main.210.pdf" class="btn">Paper</a>
			<a href="https://github.com/infotabs/infotabs" class="btn">Dataset</a>
			<a href="explore.html" class="btn">Explore</a>
			<a href="https://github.com/utahnlp/infotabs-code" class="btn">Code</a> 
			<a href="https://www.youtube.com/watch?v=YhfU1BON8EI&ab_channel=VivekGupta" class="btn">Video</a>
			<a href="https://docs.google.com/presentation/d/16wI6gWRmSry9N5caKOOH2AvJYy_6ow1XmGgWexKLQDI/edit?usp=sharing" class="btn">PPT</a><br>
		</section>
		<section class="main-content">
			<h1>Information Synchronization across Multilingual Semi-structured Tables</h1>
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>About</h2><p style="text-align: justify;"> The representation of information across languages poses significant challenges, particularly when it comes to the synchronization of semistructured data. One prominent example is Wikipedia, where the English version comprises just 11.68% of all pages despite having the highest number of editors (76%). This disparity means that a vast majority of the world's population, approximately 94%, lacks access to comprehensive information in their native language. Wikipedia pages in other languages tend to be outdated and poorly maintained. Moreover, translations on Wikipedia often suffer from inaccuracies. Ensuring accurate representation and bridging the language gap are crucial for fostering inclusivity and facilitating knowledge sharing on a global scale. Maintaining consistency and accuracy in Wikipedia tables across different languages requires meticulous attention to detail. To address these challenges and enhance the accuracy of translations, it is crucial to prioritize addressing these complexities. This will pave the way for the creation of a dependable and inclusive knowledge source that overcomes language barriers. Introducing the INFOSYNC dataset and implementing a two-step method for tabular synchronization aims to provide effective solutions to this problem.<p>
			<p style="margin-left:10%; margin-right:10%;"><img src="figures/Slide-1.png" style="max-width:95%;"></p>
			
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Procedure</h2>
			<p style="text-align: justify;">Our proposed approach for table synchronization involves two steps: (1.) Information Alignment, which focuses on aligning table rows, and (2.) Information Update, which aims to update missing or outdated rows across different language pairs to ensure consistency. In the Information Alignment step, we utilize corpus statistics from Wikipedia, considering both key and value-based similarities to align rows in multilingual tables. For the Information Update step, we employ a rule-based approach that consists of nine curated rules. These rules include row transfer, time-based updates, value trends, multikey matching, appending values, prioritizing high to low resource information, handling differences in the number of rows, and dealing with rare keys. We evaluate the effectiveness of both tasks using the INFOSYNC dataset. Additionally, we conduct an online experiment adhering to Wikipedia editing guidelines, where we submit detected mismatches for review by Wikipedia editors. We track the number of edits approved or refused by the editors. Notably, our method received acceptance and recognition on Wikipedia's Village pump, further validating its efficacy.</p>
			<h3><a id="user-content-header-3" class="anchor" href="#header-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>1) Information Alignment</h3>
			<p style="text-align: justify;">The proposed method consists of five modules aimed at aligning table rows with relaxed matching requirements to generate additional alignments.</p>
			<p style="text-align: justify;"><b>1) Corpus-based:</b> Aligns rows based on cosine similarity of their English translations, considering multiple translations using a majority voting approach. Additional context such as key values and categories are taken into account for accurate key translations.</p>
			<p style="text-align: justify;"><b>2) Key-only:</b> Attempts to align unaligned pairs from the previous module by computing cosine similarity of their English translations, with a threshold for selecting mutually most similar keys.</p>
			<p style="text-align: justify;"><b>3) Key value bidirectional:</b> Similar to the previous step, but computes similarities using the entire row (key + value) and applies a threshold for alignment.</p>
			<p style="text-align: justify;"><b>4) Key value unidirectional:</b> Relaxes the bidirectional mapping constraint by considering the highest similarity in either direction, using a higher threshold to avoid spurious alignments.</p>
			<p style="text-align: justify;"><b>5) Multi-key:</b> Allows for the selection of multiple keys (up to two) based on a threshold, with a soft constraint for value-combination alignment. Valid multi-key alignment occurs when the merge value-combination similarity score exceeds that of the most similar key.</p>
			<p style="text-align: justify;">In summary, these five modules progressively relax the matching requirements, incorporating different aspects of the table rows, to generate alignments based on cosine similarity scores.</p>
			<!-- <p style="margin-left:10%; margin-right:10%;"><img src="figures/Figure-3.png" style="max-width:95%;"></p> -->
			<h4><a id="user-content-header-4" class="anchor" href="#header-4" aria-hidden="true"><span class="octicon octicon-link"></span></a><b>Example</b></h4>
			<!-- <p style="text-align: justify; display:inline;">Below is an update example. The infobox for Shirley Strickland de la Hunty has been updated to include information in both English and Spanish. It shows rows transfer for missing information, value substitution because "Aged 78" is absent in Died. Additionally, one medal
				infomation (Bronze,1952, 100m) is added in to medal tally.</p> -->
			<p style="margin-left:10%; margin-right:10%;"><img src="figures/Slide5.png" style="max-width:95%;"></p>

			<h3><a id="user-content-header-3" class="anchor" href="#header-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>2) Information Updation</h3>
			<p style="text-align: justify;">Information modification includes Row Append (adding missing rows), Row Update (replacing or adding values), and Merge Rows. We propose a rule-based heuristic approach for information updates. These rules are applied
				sequentially according to their priority rank (P.R.). Rules explanations are described below.</p>
			<p style="text-align: justify;"><b>R1) Row Transfer:</b> Unaligned rows are transferred from one table to another.</p>
			<p style="text-align: justify;"><b>R2) Mutli-Match:</b> Updating the table by handling multi-alignments and merging information to address cases with multiple key alignments.</p>
			<p style="text-align: justify;"><b>R3) Time Based:</b> Updating aligned values using the latest timestamp to ensure the information reflects the most current data.</p>
			<p style="text-align: justify;"><b>R4) Trends (positive/negative):</b> Updating values based on identified monotonic patterns (increasing or decreasing) over time, particularly applicable to athlete career statistics.</p>
			<p style="text-align: justify;"><b>R5) Append Values:</b> Appending additional value information from an up-to-date row to update outdated rows.</p>
			<p style="text-align: justify;"><b>R6) HR to LR:</b> Transferring information from a high resource language to a low resource language to update outdated information.</p>
			<p style="text-align: justify;"><b>R7) #Rows:</b> Transferring information from a table with a greater number of rows to a table with fewer rows.</p>
			<p style="text-align: justify;"><b>R8) Non Popular Keys:</b> Updating information from a table where recently added non-popular keys are likely to exist in order to update outdated tables.</p>
			
			<h4><a id="user-content-header-4" class="anchor" href="#header-4" aria-hidden="true"><span class="octicon octicon-link"></span></a><b>Example</b></h4>
			<p style="text-align: justify; display:inline;">Below is an update example. The infobox for Shirley Strickland de la Hunty has been updated to include information in both English and Spanish. It shows rows transfer for missing information, value substitution because "Aged 78" is absent in Died. Additionally, one medal
				infomation (Bronze,1952, 100m) is added in to medal tally.</p>
			<p style="margin-left:10%; margin-right:10%;"><img src="figures/Figure-3.png" style="max-width:95%;"></p>

			<!-- <h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reasoning</h2>
			<p style="text-align: justify;">To study the nature of reasoning that is involved in deciding the relationship between a table and a hypothesis, we adapted the set of reasoning categories from <a href="https://gluebenchmark.com">GLUE Benchmark</a> to table premises. All definitions and their boundaries were verified with several rounds of discussions. Following this, three graduate students (authors of the paper) independently annotated 160 pairs from the dev and alpha 3 test sets each, and edge cases were adjudicated to arrive at consensus labels.</p>
			<figure>
				<img src="figures/reasoning.png" style="max-width:100%;">
				<figcaption>Type and counts of reasoning in the Development and test alpha3 data splits. OOT and KCS are short forms of out-of-table and Knowledge & Common Sense, respectively.
				</figcaption>
			</figure> -->
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset Statistics</h2>
			<p style="text-align: justify;">To systematically assess the challenge of information synchronization and evaluate the methodologies, we aim to build a large-scale table synchronization dataset INFOSYNC based on entity-centric Wikipedia Infoboxes.</p>
			<p style="text-align: justify;">We collected a dataset comprising approximately 99,440 infoboxes and 1,078,717 rows. The dataset included information in multiple languages, namely English, German, French, Spanish, Dutch, Arabic, Hindi, Chinese, Korean, Afrikaans, Cebuano, and Swedish. The infoboxes covered various categories such as Airport, Album, Animal, Athlete, Book, City, College, Company, Country, Diseases, Food, Medicine, Monument, Movie, Musician, Nobel, Painting, Person, Planet, Shows, and Stadium. This diverse dataset serves as the foundation for our research analysis and experimentation.</p>
			<!-- <div>
				<table  style="margin-left:15%;
					margin-right:15%;">
					<thead>
						<tr>
							<th>Data Split</th>
							<th>Number of Tables</th>
							<th>Number of Pairs</th>
						</tr>
					</thead>
					<tbody align="center">
						<tr>
							<td>Train</td>
							<td>1740</td>
							<td>16538</td>
						</tr>
						<tr>
							<td>Dev</td>
							<td>200</td>
							<td>1800</td>
						</tr>
						<tr>
							<td>alpha 1</td>
							<td>200</td>
							<td>1800</td>
						</tr>
						<tr>
							<td>alpha 2</td>
							<td>200</td>
							<td>1800</td>
						</tr>
						<tr>
							<td>alpha 3</td>
							<td>200</td>
							<td>1800</td>
						</tr>
					</tbody>
					<caption>Number of tables and premise-hypothesis
					pairs for each data split</caption>
				</table>
			</div> -->
			<br>
			<!-- <div style="text-align:center;">
				<table>
					<thead>
						<tr>
							<th>Data Split</th>
							<th>Cohen's Kappa</th>
							<th>Human Performance</th>
							<th>Majority Agreeement</th>
						</tr>
					</thead>
					<tbody align="center">
						<tr>
							<td>Dev</td>
							<td>0.78</td>
							<td>79.78</td>
							<td>93.53</td>
						</tr>
						<tr>
							<td>alpha 1</td>
							<td>0.80</td>
							<td>84.04</td>
							<td>97.48</td>
						</tr>
						<tr>
							<td>alpha 2</td>
							<td>0.80</td>
							<td>83.88</td>
							<td>96.77</td>
						</tr>
						<tr>
							<td>alpha 3</td>
							<td>0.74</td>
							<td>79.33</td>
							<td>95.58</td>
						</tr>
					</tbody>
					<caption>Cohen's Kappa, human baseline and inter-annotator agreement scores</caption>
				</table>
			</div> -->
			<p style="margin-left:10%; margin-right:10%;"><img src="figures/graph_data.png" style="max-width:95%;"></p>
			<h3><a id="user-content-header-3" class="anchor" href="#header-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>2) Test Set</h3>
			<p style="text-align: justify;">We created test sets to evaluate the alignment accuracy of our pipeline between different languages.</p>

			<h4><a id="user-content-header-4" class="anchor" href="#header-4" aria-hidden="true"><span class="octicon octicon-link"></span></a>i) Translations Based Test Set:</h4>
			<p style="text-align: justify;">For the translation-based test sets, we utilized translations and covered approximately 1500 tables for both English to X alignments and X to Y alignments. Here, X and Y represent languages other than English. In these test sets, we initially obtained preliminary alignments from our alignment pipeline and stored them in a JSON file. Our task was to review and verify the correctness of these alignments, making necessary updates to the JSON file as needed.</p>

			<h4><a id="user-content-header-4" class="anchor" href="#header-4" aria-hidden="true"><span class="octicon octicon-link"></span></a>ii) True Test Set:</h4>
			<p style="text-align: justify;">Similarly, for the true test set, we followed a similar approach of alignment verification but without the use of translations. In this case, we focused on evaluating the alignments between English and Hindi, covering around 200 tables, as well as between English and Chinese, also covering approximately 200 tables.</p>

			<p style="text-align: justify;">Through these test sets, we aimed to assess the accuracy and reliability of the alignment pipeline by comparing the alignments generated against the expected alignments. This process helped us validate the effectiveness of our alignment techniques and improve the quality of the generated alignments.</p>

			<h3><a id="user-content-header-3" class="anchor" href="#header-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>3) Metadata</h3>

			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Live Test</h2>
			<p style="text-align: justify;">The rules described in information updation section are applied to support human editors in updating Wikipedia infoboxes. Following Wikipedia's guidelines, rule set, and policies, our update requests include a detailed description with evidence. This evidence consists of the up-to-date entity page URL in the source language, the specific table rows information along with the source language, details of the proposed changes, and an additional citation provided by the editor for further validation. Additionally, our information alignment method allows for updates that go beyond the heuristic-based rules, ensuring alignment with the updated information.</p>
			<div>
				<table  style="margin-left:15%;
					margin-right:15%;">
					<thead>
						<tr>
							<th></th>
							<th>Accepted</th>
							<th>Rejected</th>
							<th>Total</th>
						</tr>
					</thead>
					<tbody align="center">
						<tr>
							<td>Eng => X</td>
							<td>161</td>
							<td>43</td>
							<td>204</td>
						</tr>
						<tr>
							<td>X => Y</td>
							<td>169</td>
							<td>47</td>
							<td>216</td>
						</tr>
						<tr>
							<td>X => English</td>
							<td>136</td>
							<td>47</td>
							<td>183</td>
						</tr>
						<tr>
							<td>Total</td>
							<td>466</td>
							<td>137</td>
							<td>603</td>
						</tr>
					</tbody>
					<br>
					<!-- <caption>Number of tables and premise-hypothesis
					pairs for each data split</caption> -->
				</table>
			</div>
			<!-- <br><br>
			<div style="text-align:center;">
				<table>
					<thead>
						<tr>
							<th>Data Split</th>
							<th>Cohen's Kappa</th>
							<th>Human Performance</th>
							<th>Majority Agreeement</th>
						</tr>
					</thead>
					<tbody align="center">
						<tr>
							<td>Dev</td>
							<td>0.78</td>
							<td>79.78</td>
							<td>93.53</td>
						</tr>
						<tr>
							<td>alpha 1</td>
							<td>0.80</td>
							<td>84.04</td>
							<td>97.48</td>
						</tr>
						<tr>
							<td>alpha 2</td>
							<td>0.80</td>
							<td>83.88</td>
							<td>96.77</td>
						</tr>
						<tr>
							<td>alpha 3</td>
							<td>0.74</td>
							<td>79.33</td>
							<td>95.58</td>
						</tr>
					</tbody>
					<caption>Cohen's Kappa, human baseline and inter-annotator agreement scores</caption>
				</table>
			</div> -->
			<!-- <h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Knowledge + InfoTabS</h2>
			<p style="text-align: justify;"> You should check our <a href="https://2021.naacl.org/">NAACL 2021</a> paper which <a href="https://knowledge-infotabs.github.io">enhance InfoTabS</a> with extra Knowledge.</p>
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>TabPert</h2>
			<p style="text-align: justify;"> You should check our <a href="https://2021.emnlp.org">EMNLP 2021</a> paper which is a <a href="https://tabpert.github.io">tabular perturbation platform</a> to generate counterfactual examples.</p> -->

			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>People</h2>
			<p style="text-align: justify;"> The INFOTABS dataset is prepared at the <a href="https://www.cs.utah.edu/"> School of Computing</a> of <a href="https://www.cs.utah.edu/">University of Utah</a> by the following people: </p>
			<figure>
				<img src="figures/vivekg.jpg" style="width:25%;">
				<img src="figures/maitrey.jpeg" style="width:25%;">
				<img src="figures/pegah.png" style="width:21%;">
				<img src="figures/viveks.jpg" style="width:23%;">
				<figcaption>From left to right, <a href="https://vgupta123.github.io">Vivek Gupta</a>, <a href="https://sites.google.com/view/maitreymehta/home">Maitrey Mehta</a>, <a href="https://sites.google.com/view/pnokhiz/home">Pegah Nokhiz</a> and <a href="https://svivek.com/">Vivek Srikumar</a>. </figcaption>
			</figure>
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Citation</h2>
			<p style="text-align: justify;"> Please cite our paper as below if you use the INFOTABS dataset.</p>
			<pre><code>@inproceedings{gupta-etal-2020-infotabs,
    title = "{INFOTABS}: Inference on Tables as Semi-structured Data",
    author = "Gupta, Vivek  and
      Mehta, Maitrey  and
      Nokhiz, Pegah  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.210",
    pages = "2309--2324",
    abstract = "In this paper, we observe that semi-structured tabulated text is ubiquitous; understanding them requires not only comprehending the meaning of text fragments, but also implicit relationships between them. We argue that such data can prove as a testing ground for understanding how we reason about information. To study this, we introduce a new dataset called INFOTABS, comprising of human-written textual hypotheses based on premises that are tables extracted from Wikipedia info-boxes. Our analysis shows that the semi-structured, multi-domain and heterogeneous nature of the premises admits complex, multi-faceted reasoning. Experiments reveal that, while human annotators agree on the relationships between a table-hypothesis pair, several standard modeling strategies are unsuccessful at the task, suggesting that reasoning about tables can pose a difficult modeling challenge.",
}</code></pre>
			<h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Acknowledgement</h2>
			<p style="text-align: justify;">Authors thank members of the <a href="https://svivek.com/">Utah NLP group</a> for their valuable insights and
			suggestions at various stages of the project; and <a href="https://2023.aclweb.org/">ACL 2023</a> reviewers for pointers to
			related works, corrections, and helpful comments. Authors thank the largest free resource <a href="https://en.wikipedia.org/wiki/Main_Page"> Wikipedia</a> for InfoSync tables.</p>
			<footer class="site-footer">
				<span class="site-footer-owner"><a href="https://github.com/Info-Sync/InfoSync">INFOSYNC</a> is maintained by <a href="https://vgupta123.github.io">Vivek Gupta</a>.</span>
				<span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman</a> theme by <a href="https://github.com/jasonlong">jasonlong</a>.</span>
			</footer>
		</section>
	</body>
</html>
